# 1. Projeto

Este projeto se trata de um teste para vaga de Desenvolvimento Back-end .NET na empresa Nexer. Este teste trata-se de criar uma API REST para gerenciar faturamento de clientes, com as caracter√≠sticas descritas abaixo.

**Funcionalidades üõ†Ô∏è**

* Customer:¬†CRUD;‚Ä®Criar um cadastro do cliente com os seguintes campos:
    * Id;
    * Name;
    * Email;
    * Address;
    * **Todos¬†os campos s√£o de preenchimento obrigat√≥rio.**
* Produtos:¬†CRUD;‚Ä®Criar um cadastro de produtos com os seguintes campos:
    * Id;
    * Nome do produto;
    * **Todos¬†os campos s√£o de preenchimento obrigat√≥rio.**
* Controle de confer√™ncia e importa√ß√£o de billing.
    * Utilizar postman para consulta dos dados da API‚Äôs para cria√ß√£o das tabelas de billing e billingLines.
	  * Ap√≥s consulta, e cria√ß√£o do passo anterior, inserir no banco de dados o primeiro registro do retorno da API de billing para cria√ß√£o de cliente e produto atrav√©s do swagger ou dataseed.

    * Utilizar as API‚Äôs para consumo dos dados a partir da aplica√ß√£o que est√° criada e fazer as seguintes verifica√ß√µes:
      * Se o cliente e o produto existirem, inserir o registro do billing e billingLines no DB local.
      * Caso se o cliente existir ou s√≥ o produto existir, deve retornar um erro na aplica√ß√£o informando sobre a cria√ß√£o do registro faltante.
      * Criar exceptions tratando mal funcionamento ou interrup√ß√£o de servi√ßo quando API estiver fora.
* Lista de API‚Äôs :
	* Get https://65c3b12439055e7482c16bca.mockapi.io/api/v1/billing
	* Get https://65c3b12439055e7482c16bca.mockapi.io/api/v1/billing/:id
	* Post https://65c3b12439055e7482c16bca.mockapi.io/api/v1/billing
	* Delete https://65c3b12439055e7482c16bca.mockapi.io/api/v1/billing/:id
	* PUT https://65c3b12439055e7482c16bca.mockapi.io/api/v1/billing/:id

**Requisitos üíª**

* A aplica√ß√£o dever√° ser desenvolvida usando .NET a partir da vers√£o 5+;
* Modelagem de dados pode ser no banco de dados de sua prefer√™ncia, podendo ser um banco relacional ou n√£o relacional (mongodb, SQL Server, PostgreSQL, MySQL, etc);
* Persist√™ncia de dados no banco dever√° ser feita utilizando o Entity Framework Core;
* O retorno da API dever√° ser em formato JSON;
* Utilizar as requisi√ß√µes GET, POST, PUT ou DELETE, conforme a melhor pr√°tica;
* Criar o README do projeto descrevendo as tecnologias utilizadas, chamadas dos servi√ßos e configura√ß√µes necess√°rio para executar a aplica√ß√£o.

**Pontos Extras ‚≠ê**

* Desenvolvimento baseado em TDD;
* Pr√°ticas de modelagem de projeto;
* Criar e configurar o Swagger da API de acordo com as melhores pr√°ticas;
* Criar uma API para extra√ß√£o dos dados de faturamento.
* Sugest√µes ser√£o bem vindas.

**Submiss√£o do teste üìù**

Crie um fork do teste para acompanharmos o seu desenvolvimento atrav√©s dos seus commits.

# 2. Solu√ß√£o

## 2.1. Arquitetura, Tecnologias e Funcionalidades

### 2.1.1. CQRS

O projeto foi constru√≠do seguindo os princ√≠pios do CQRS, onde as opera√ß√µes de leitura (*queries*) s√£o separadas das opera√ß√µes de escrita (*commands*), permitindo maior escalabilidade, otimiza√ß√£o de desempenho e flexibilidade na modelagem dos dados.

Al√©m disso, utilizamos **Cache Distribu√≠do** (com Redis) para armazenar os resultados das consultas, reduzindo a carga no banco de dados e melhorando a efici√™ncia das opera√ß√µes de leitura. As opera√ß√µes de atualiza√ß√µes do *cache* est√£o em **Notifications** do **MediatR**, garantindo que os dados armazenados reflitam as altera√ß√µes realizadas no sistema.

Os *commands* s√£o: 

- Customers: 
  - `CreateCustomerCommand` que √© respons√°vel por criar um novo `Customer`;
  - `UpdateCustomerCommand` que √© respons√°vel por atualizar um `Customer` existente.
- Products:
  - `CreateProductCommand` que √© respons√°vel por criar um novo `Product`;
  - `UpdateProductCommand` que √© respons√°vel por atualizar um `Product` existente.
- Billings: 
  - `ImportBillingCommand` que √© respons√°vel por importar (da API externa) os `Billings` e `BillingLines` existentes.

As *queries*:

- Customers: 
  - `GetAllCustomerQuery` que √© respons√°vel por obter `Customers` de forma paginada;
  - `GetCustomerByIdQuery` que √© respons√°vel por obter um `Customer` pelo seu identificador.
- Products: 
  - `GetAllProductQuery` que √© respons√°vel por obter `Products` de forma paginada;
  - `GetProductByIdQuery` que √© respons√°vel por obter um `Product` pelo seu identificador.

E as *notifications*:
- `DeleteAllPaginatedEntityInCacheNotification` que deleta todos os dados paginados em *cache* quando h√° altera√ß√µes no banco; 
- `UpdateEntityInCacheNotification` que atualiza uma entidade *cache* quando ela √© consultada no banco, criada ou alterada;
- `UpdatePaginateEntityInCacheNotification` que atualiza entidades paginadas em *cache* quando √© feita uma consulta paginada no banco de dados.

Quando ocorre uma altera√ß√£o no banco de dados, seja um create ou update de Customer ou Product, a informa√ß√£o √© atualizada no cache e todos os dados paginados s√£o removidos. Isso garante que a pagina√ß√£o n√£o exiba informa√ß√µes desatualizadas, j√° que os dados armazenados anteriormente n√£o refletem as novas inser√ß√µes ou modifica√ß√µes. Al√©m disso, as consultas ao banco de dados relacional s√£o seguidas pelo armazenamento dos resultados no cache, permitindo que consultas subsequentes recuperem os dados diretamente do Redis, reduzindo a carga no banco de dados e melhorando a performance do sistema.

### 2.1.2. Middleware de Exceptions 

No projeto foi desenvolvido um *middleware* para tratar *exceptions* de forma global, o `ExceptionMiddleware` (presente no projeto de API). Para cada tipo de *exception* mapeada cont√©m uma classe *handle* que trata a resposta de forma diferente para cada um dos tipos de *exception*. Algumas das *exceptions* mapeadas s√£o: 

- `ApiExceptionHandler`, um *handle* para um *exception* customizado (`ApiException`) para tratar o erro de API externa de *billing*;
- `BusinessExceptionHandler`, tamb√©m customizado para tratar erros de neg√≥cio (`BusinessException`);
- `CustomUnsupportedApiVersionExceptionHandler` que trata o erro para o tipo de *exception* `CustomUnsupportedApiVersionException`, esta que tamb√©m √© customizada e √© lan√ßada quando o usu√°rio tenta acessar uma vers√£o n√£o existente da rota (a API cont√©m versionamento de *endpoints*);
- `ValidationExceptionHandler` que trata de erros `ValidationException`, um tipo de *exception* gerada quando a valida√ß√£o do *Fluent Validation* n√£o √© satisfeita.

Al√©m de tratar resposta, os *handlers* tamb√©m s√£o utilizados para registrar *logs* no SEQ/arquivo/terminal com o erro, motivo, *trace*, entre outros dados.

### 2.1.3. Versionamento de API

O projeto conta com versionamento de *endpoints*, onde a vers√£o √© especificada na URL da requisi√ß√£o (*path*) e tamb√©m inclu√≠da nos *response headers*. Essa abordagem garante maior controle sobre a evolu√ß√£o da API, permitindo a manuten√ß√£o de diferentes vers√µes simultaneamente sem impactar consumidores existentes.

### 2.1.4. Valida√ß√£o de dados da requisi√ß√£o

Utilizamos **FluentValidation** para validar todas as requisi√ß√µes do **CRUD**, garantindo que mensagens de erro claras sejam retornadas ao cliente.

A valida√ß√£o √© centralizada no *behavior* `ValidationBehavior.cs`, uma camada intermedi√°ria entre o *controller* e o os *handlers* do **MediatR**. Essa abordagem elimina a necessidade de incluir valida√ß√µes diretamente nos *handlers*, refor√ßando o **Princ√≠pio da Responsabilidade √önica** (SRP). Dessa forma, o *handler* permanece focado exclusivamente em executar sua l√≥gica principal, enquanto o *behavior* gerencia a valida√ß√£o das requisi√ß√µes de forma desacoplada e reutiliz√°vel.

### 2.1.5. Valida√ß√£o de performance do Handle

Implementamos no projeto um mecanismo de verifica√ß√£o de performance para cada *command* e *query* *handler*. No `appsettings.json`, registramos o tempo m√©dio de execu√ß√£o esperado para cada *handler* em milissegundos. Com base nisso, o *behavior* `PerformanceBehavior` monitora a execu√ß√£o e compara com o tempo m√©dio definido. Caso o tempo exceda o limite estabelecido, um *warning* *log* √© gerado, alertando sobre a poss√≠vel degrada√ß√£o de desempenho na respectiva rota.

Essa verifica√ß√£o √© fundamental para identificar gargalos de performance, seja no acesso ao banco de dados, na comunica√ß√£o com servi√ßos externos ou at√© mesmo em opera√ß√µes internas dentro do *cluster*, permitindo otimiza√ß√µes proativas no sistema.

### 2.1.6. Convers√£o de objetos com AutoMapper

Utilizamos AutoMapper para automatizar a convers√£o entre DTOs e entidades, reduzindo a necessidade de mapeamentos manuais e tornando o c√≥digo mais limpo e manuten√≠vel.

### 2.1.7. Serilog e SEQ

Utilizamos SEQ em conjunto com Serilog para centralizar e visualizar os *logs*, facilitando o monitoramento e a depura√ß√£o do sistema de forma eficiente. Os *logs* s√£o registrados no SEQ, arquivo e terminal.

### 2.1.8. Retry com Polly

Para a integra√ß√£o com a API de *billing*, utilizamos o `HttpClient` em conjunto com a estrat√©gia de *retry* da biblioteca **Polly**. Esse mecanismo permite que, em caso de falha na chamada externa, a requisi√ß√£o seja reexecutada automaticamente at√© tr√™s vezes, com um intervalo exponencial entre as tentativas. O tempo de espera segue a f√≥rmula $2^N$  segundos, onde $N$ representa o n√∫mero da tentativa atual. Dessa forma, a primeira repeti√ß√£o ocorre ap√≥s 2 segundos, a segunda ap√≥s 4 segundos e a terceira ap√≥s 8 segundos, aumentando gradualmente o tempo de espera para evitar sobrecarga no servi√ßo externo.

### 2.1.9. PostgreSQL com EF e Repositorio Gen√©rico

O projeto utiliza **PostgreSQL** como banco de dados, em conjunto com o E**ntity Framework Core** para o mapeamento objeto-relacional (ORM). As configura√ß√µes e altera√ß√µes no banco s√£o gerenciadas por meio de *migrations*.

Al√©m disso, adotamos um reposit√≥rio gen√©rico para todas as entidades do sistema, promovendo reutiliza√ß√£o de c√≥digo e padroniza√ß√£o no acesso aos dados. Esse reposit√≥rio encapsula as opera√ß√µes comuns de CRUD (*Create, Read, Update, Delet*e), proporcionando uma camada de abstra√ß√£o a dados.

### 2.1.10. Centraliza√ß√£o de mensagens de erro

Centralizamos todas as mensagens de erro em arquivos de recursos (`.resx`), permitindo uma manuten√ß√£o mais organizada e facilitando a reutiliza√ß√£o das mensagens em diferentes partes do sistema. Essa abordagem melhora a padroniza√ß√£o, evita duplica√ß√£o de c√≥digo e simplifica futuras altera√ß√µes, al√©m de possibilitar a localiza√ß√£o (*localization*), caso seja necess√°rio oferecer suporte a m√∫ltiplos idiomas futuramente.

### 2.1.11. Swagger

Tamb√©m utilizamos o Swagger para a documenta√ß√£o da API, facilitando a visualiza√ß√£o e o consumo dos *endpoints*. Al√©m disso, enriquecemos essa documenta√ß√£o incluindo descri√ß√µes detalhadas, respostas esperadas e exemplos, utilizando o XML gerado a partir dos coment√°rios no c√≥digo-fonte (C# XML Docs). Essa abordagem melhora a clareza da documenta√ß√£o, tornando mais f√°cil para desenvolvedores entenderem e interagirem com a API de forma eficiente.

### 2.1.12. Docker e Kubernetes

No projeto, foi elaborado um **Dockerfile** dentro da API para a constru√ß√£o da imagem Docker correspondente, que foi posteriormente publicada no reposit√≥rio [`ellisonguimaraes/billing-api:v2`](https://hub.docker.com/r/ellisonguimaraes/billing-api). Al√©m da cria√ß√£o da imagem Docker, foram desenvolvidos diversos recursos para possibilitar a execu√ß√£o do projeto em um *cluster* local utilizando o **Kind**.

> ‚ö†Ô∏è **Observa√ß√£o:** \
> Todos os arquivos referente ao Kubernetes est√£o na pasta `\k8s`.

#### üìå Manifesto `seq.yaml`: 
Respons√°vel pela implanta√ß√£o do servidor de *logs* **SEQ** no *cluster*, contendo:
- Uma **Secret** denominada `seq-secret`, que armazena as credenciais de acesso (usu√°rio e senha) ao SEQ;
- Um **StatefulSet** chamado `seq`, contendo a configura√ß√£o do servidor de *logs* **SEQ**;
- Um **Service** `seq-service` do tipo **NodePort**, que exp√µe o SEQ externamente ao *cluster* na porta `30004`.

#### üìå Manifesto `redis.yaml`:
Define a implanta√ß√£o do **Redis** para *cache* distribu√≠do no *cluster*, contendo:
- Uma **Secret** `redis-secret` e um **ConfigMap** `redis-config`, que armazenam as informa√ß√µes de credenciais e configura√ß√£o do Redis;
- Um **StatefulSet** denominado `redis`, respons√°vel pela execu√ß√£o do Redis;
- Um **Service** `redis-service` do tipo **NodePort**, permitindo acesso externo ao Redis atrav√©s da porta `30003`.

#### üìå Manifesto `postgres.yaml`:
Define a configura√ß√£o do banco de dados **PostgreSQL** dentro do *cluster*, incluindo:
- Uma **Secret** `postgres-secret` e um **ConfigMap** `postgres-config`, que armazenam as credenciais de acesso (usu√°rio, senha e banco de dados);
- Um **StatefulSet** `postgres`, contendo a imagem do PostgreSQL;
- Um **Service** `postgres-service` do tipo **NodePort**, que permite o acesso externo ao banco de dados pela porta `30002`.

#### üìå Manifesto `ingress-nginx.yaml`:
Respons√°vel pela instala√ß√£o do **Nginx Ingress Controller**, configurado para expor o *ingress* na porta `30000`.  
> ‚ö†Ô∏è **Observa√ß√£o:** Este √© o primeiro manifesto que deve ser aplicado ao *cluster*.

#### üìå Manifesto `deployment.yaml`:
Define a implanta√ß√£o da aplica√ß√£o, contendo:
- Um **Deployment** que instancia a aplica√ß√£o utilizando a imagem `ellisonguimaraes/billing-api:v2`.
- Um **Service** `billing-api-service` do tipo **ClusterIP**, tornando a aplica√ß√£o acess√≠vel via *ingress*.
- Um **ConfigMap** `billing-api-config`, contendo as *strings* de conex√£o com o PostgreSQL, Redis e SEQ.

O *deployment* deste projeto inclui tr√™s tipos de ***probes*** para monitoramento e garantir a disponibilidade da aplica√ß√£o:

- **Liveness Probe**: Respons√°vel por verificar se a aplica√ß√£o est√° em execu√ß√£o. Para isso, ela realiza requisi√ß√µes √† rota de *health check* `/health`. Caso a verifica√ß√£o falhe, o Kubernetes entende que o cont√™iner est√° travado ou n√£o responde corretamente e realiza sua reinicializa√ß√£o autom√°tica.
- **Readiness Probe**: Utilizada para determinar se a aplica√ß√£o est√° pronta para receber requisi√ß√µes, tamb√©m atrav√©s do *health check*. Enquanto essa verifica√ß√£o n√£o for bem-sucedida, o Kubernetes n√£o encaminha tr√°fego para o pod, evitando que requisi√ß√µes sejam enviadas para inst√¢ncias ainda em processo de inicializa√ß√£o ou que n√£o estejam operacionais.
- **Startup Probe**: Garantia de que a aplica√ß√£o tenha tempo suficiente para iniciar antes que as outras probes comecem a atuar. Essa probe √© especialmente √∫til para aplica√ß√µes que possuem um tempo de inicializa√ß√£o mais longo, evitando que o Kubernetes reinicie o cont√™iner prematuramente.

#### üìå Manifesto `ingress.yaml`:
Define o **Ingress**, respons√°vel por expor a aplica√ß√£o e direcionar o tr√°fego para o *Service* `billing-api-service`. Como o **Nginx Ingress Controller** est√° mapeado na porta `30000`, a aplica√ß√£o aqui desenvolvida ser√° acess√≠vel por esta porta.


## 3. Executando a Aplica√ß√£o

### 3.1. Atrav√©s dos arquivos manifestos Kubernetes

> ‚ö†Ô∏è **Observa√ß√£o:** \
> Todos os arquivos referente ao Kubernetes est√£o na pasta `\k8s`.

Para que o projeto funcione corretamente, √© necess√°rio ter os seguintes componentes instalados:  

1. **Docker** instalado na m√°quina;
2. **kubectl**, a ferramenta de linha de comando do Kubernetes. Para instalar, consulte a documenta√ß√£o oficial: [Kubernetes CLI](https://kubernetes.io/docs/tasks/tools/);
3. **Kind** (Kubernetes in Docker), utilizado para criar um *cluster* local. O guia de instala√ß√£o pode ser encontrado em: [Kind Quick Start](https://kind.sigs.k8s.io/docs/user/quick-start/#installation).  

O primeiro passo √© criar um *cluster* local utilizando o **Kind**. Para isso, use o arquivo de configura√ß√£o `kind-config.yaml` e execute o seguinte comando:  

```shell
kind create cluster --name cluster-nexer --config kind-config.yaml
```

Ap√≥s a cria√ß√£o do *cluster*, √© necess√°rio aplicar os arquivos de manifesto na ordem correta. Isso pode ser feito utilizando o comando abaixo:

```sh
kubectl apply -f <file_name>.yaml
```

> Para que o arquivo `ingress.yaml` consiga ser aplicado, a instala√ß√£o do ***Nginx Ingress Controller*** (do arquivo `ingress-nginx.yaml`) precisa estar rodando e funcional, ou seja, pode demorar um pouco at√© finalizar a instala√ß√£o.

Para cada um dos arquivos, seguindo esta ordem:

1. `ingress-nginx.yaml`;
2. `seq.yaml`;
3. `redis.yaml`;
4. `postgres.yaml`;
5. `deployment.yaml`.
6. `ingress.yaml`;

O arquivo `kind-config.yaml` na cria√ß√£o do *cluster* local expoe externamente para acesso as portas:
- `30000` referente ao *ingress* que aponta para nossa aplica√ß√£o desenvolvida, logo voc√™ pode acessar atrav√©s desta porta a aplica√ß√£o; 
- `30002` do PostgreSQL. Caso queira acessar localmente basta acessar com o `localhost` com a porta, o usu√°rio `user01` e a senha `Abcd@1234`; 
- `30003` do Redis, onde basta acessar localmente pela porta utilizando a senha `Abcd@1234`; 
- `30004` do SEQ, que pode acessar atrav√©s do navegador com a porta, onde o primeiro *login* √© necess√°rio ser feito utilizando as credenciais `admin` com senha `Abcd@1234`.

### 3.2. Atrav√©s dos arquivos do projeto

Para executar o projeto localmente, √© necess√°rio ter os seguintes componentes instalados:

- **.NET 8.0** (dotnet), garantindo compatibilidade com a aplica√ß√£o;
- **Redis**, utilizado para cache distribu√≠do;
- **PostgreSQL**, que servir√° como banco de dados principal;
- O servidor de *logs* **SEQ**, para monitoramento da aplica√ß√£o.

Ap√≥s isso, basta configurar no arquivo `appsettings.json` no projeto de API as conex√µes para cada um dos componentes acima, utilizando:

- O `ConnectionStrings.DefaultConnection` para a *string* de conex√£o do **PostgreSQL**;
- O `Serilog.WriteTo[0].Args.serverUrl` para definir conex√£o do **SEQ**;
- O `RedisSettings.Host` para definir o *host* do **Redis**.

E com isso, aplicar o `dotnet build` e `dotnet run` no projeto, podendo acessar o projeto no `localhost:5000` (**Swagger**).